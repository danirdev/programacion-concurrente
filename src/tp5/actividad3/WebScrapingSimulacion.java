package tp5.actividad3;

import java.time.LocalTime;
import java.time.format.DateTimeFormatter;
import java.util.ArrayList;
import java.util.List;

/**
 * Clase principal que simula web scraping concurrente de noticias usando interfaz Runnable.
 * Crea 10 hilos para procesar simult√°neamente 10 noticias de El Tribuno de Jujuy,
 * extrae el contenido espec√≠fico y mide el tiempo de ejecuci√≥n.
 */
public class WebScrapingSimulacion {
    
    public static void main(String[] args) {
        DateTimeFormatter timeFormatter = DateTimeFormatter.ofPattern("HH:mm:ss.SSS");
        String tiempo = LocalTime.now().format(timeFormatter);
        
        System.out.println("=".repeat(80));
        System.out.println("        WEB SCRAPING CONCURRENTE CON INTERFAZ RUNNABLE");
        System.out.println("=".repeat(80));
        System.out.println("[" + tiempo + "] Iniciando simulaci√≥n de web scraping...");
        System.out.println();
        System.out.println("CONFIGURACI√ìN DEL SISTEMA:");
        System.out.println("‚Ä¢ Implementaci√≥n: Interfaz Runnable");
        System.out.println("‚Ä¢ Fuente: El Tribuno de Jujuy - Secci√≥n Policiales");
        System.out.println("‚Ä¢ Noticias a procesar: 10");
        System.out.println("‚Ä¢ Hilos concurrentes: 10 (uno por noticia)");
        System.out.println("‚Ä¢ Objetivo: Extraer contenido de <div amp-access=\"noticia\">");
        System.out.println("‚Ä¢ Medici√≥n: Tiempo total de ejecuci√≥n");
        System.out.println("=".repeat(80));
        System.out.println();
        
        // Registrar tiempo de inicio
        long tiempoInicioTotal = System.currentTimeMillis();
        
        // Obtener array de enlaces de noticias
        String[] enlaces = GestorEnlaces.obtenerEnlaces();
        
        // Mostrar informaci√≥n de los enlaces
        GestorEnlaces.mostrarInformacionEnlaces();
        
        // Validar enlaces antes de procesar
        if (!GestorEnlaces.validarEnlaces()) {
            System.err.println("‚ùå Error: Se encontraron enlaces inv√°lidos. Abortando ejecuci√≥n.");
            return;
        }
        
        System.out.println("‚úÖ Validaci√≥n de enlaces completada exitosamente");
        System.out.println();
        
        // Crear listas para gestionar las tareas y hilos
        List<ScrapingTask> tareas = new ArrayList<>();
        List<Thread> hilos = new ArrayList<>();
        
        // Crear 10 tareas Runnable, una para cada noticia
        tiempo = LocalTime.now().format(timeFormatter);
        System.out.println("[" + tiempo + "] üîß Creando tareas de scraping...");
        
        for (int i = 0; i < enlaces.length; i++) {
            ScrapingTask tarea = new ScrapingTask(enlaces, i);
            tareas.add(tarea);
            
            // Crear hilo para cada tarea usando Runnable
            Thread hilo = new Thread(tarea, "Scraper-" + String.format("%02d", i + 1));
            hilos.add(hilo);
            
            System.out.println("   ‚úÖ Tarea " + (i + 1) + "/10 creada para: " + 
                             enlaces[i].substring(0, Math.min(enlaces[i].length(), 50)) + "...");
        }
        
        System.out.println();
        tiempo = LocalTime.now().format(timeFormatter);
        System.out.println("[" + tiempo + "] üöÄ INICIANDO SCRAPING CONCURRENTE");
        System.out.println("=".repeat(50));
        
        // Registrar tiempo de inicio del scraping
        long tiempoInicioScraping = System.currentTimeMillis();
        
        // Iniciar todos los hilos simult√°neamente
        for (int i = 0; i < hilos.size(); i++) {
            Thread hilo = hilos.get(i);
            hilo.start();
            System.out.println("üîÑ " + hilo.getName() + " iniciado para noticia " + (i + 1));
            
            // Peque√±o delay para evitar sobrecarga inicial
            try {
                Thread.sleep(50);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }
        
        System.out.println();
        System.out.println("‚è≥ Esperando que todos los hilos completen el scraping...");
        System.out.println("üì∞ Los resultados aparecer√°n conforme cada hilo termine:");
        System.out.println();
        
        // Esperar a que todos los hilos terminen
        for (Thread hilo : hilos) {
            try {
                hilo.join(); // Esperar a que termine cada hilo
            } catch (InterruptedException e) {
                System.err.println("‚ùå Interrupci√≥n durante la espera del hilo: " + hilo.getName());
                Thread.currentThread().interrupt();
            }
        }
        
        // Calcular tiempos de ejecuci√≥n
        long tiempoFinScraping = System.currentTimeMillis();
        long tiempoFinTotal = System.currentTimeMillis();
        
        long tiempoScraping = tiempoFinScraping - tiempoInicioScraping;
        long tiempoTotal = tiempoFinTotal - tiempoInicioTotal;
        
        // Mostrar estad√≠sticas finales
        mostrarEstadisticasFinales(tareas, tiempoScraping, tiempoTotal);
        
        // Demostrar ventajas de Runnable para web scraping
        demostrarVentajasRunnable(tareas, tiempoScraping);
    }
    
    /**
     * Muestra las estad√≠sticas finales del web scraping
     */
    private static void mostrarEstadisticasFinales(List<ScrapingTask> tareas, 
                                                  long tiempoScraping, 
                                                  long tiempoTotal) {
        DateTimeFormatter timeFormatter = DateTimeFormatter.ofPattern("HH:mm:ss.SSS");
        String tiempo = LocalTime.now().format(timeFormatter);
        
        System.out.println();
        System.out.println("=".repeat(80));
        System.out.println("                 ESTAD√çSTICAS FINALES DE WEB SCRAPING");
        System.out.println("=".repeat(80));
        System.out.println("[" + tiempo + "] Scraping completado");
        System.out.println();
        
        // Contar resultados
        int exitosos = 0;
        int errores = 0;
        long tiempoMinimo = Long.MAX_VALUE;
        long tiempoMaximo = 0;
        long tiempoTotalTareas = 0;
        
        for (ScrapingTask tarea : tareas) {
            if (tarea.isExitoso()) {
                exitosos++;
            } else {
                errores++;
            }
            
            long tiempoTarea = tarea.getTiempoEjecucion();
            tiempoTotalTareas += tiempoTarea;
            
            if (tiempoTarea < tiempoMinimo) {
                tiempoMinimo = tiempoTarea;
            }
            if (tiempoTarea > tiempoMaximo) {
                tiempoMaximo = tiempoTarea;
            }
        }
        
        // Estad√≠sticas generales
        System.out.println("üìä ESTAD√çSTICAS GENERALES:");
        System.out.println("   Total de noticias: " + tareas.size());
        System.out.println("   Procesadas exitosamente: " + exitosos);
        System.out.println("   Errores: " + errores);
        System.out.println("   Tasa de √©xito: " + String.format("%.1f%%", (exitosos * 100.0 / tareas.size())));
        System.out.println();
        
        // Estad√≠sticas de tiempo
        System.out.println("‚è±Ô∏è ESTAD√çSTICAS DE TIEMPO:");
        System.out.println("   Tiempo total del programa: " + tiempoTotal + "ms (" + 
                          String.format("%.3f", tiempoTotal / 1000.0) + "s)");
        System.out.println("   Tiempo de scraping concurrente: " + tiempoScraping + "ms (" + 
                          String.format("%.3f", tiempoScraping / 1000.0) + "s)");
        
        if (exitosos > 0) {
            double tiempoPromedio = tiempoTotalTareas / (double) tareas.size();
            System.out.println("   Tiempo promedio por noticia: " + String.format("%.0f", tiempoPromedio) + "ms");
            System.out.println("   Tiempo m√≠nimo: " + tiempoMinimo + "ms");
            System.out.println("   Tiempo m√°ximo: " + tiempoMaximo + "ms");
        }
        System.out.println();
        
        // An√°lisis de rendimiento
        System.out.println("‚ö° AN√ÅLISIS DE RENDIMIENTO:");
        double tiempoSecuencial = tiempoTotalTareas; // Si se hubiera hecho secuencialmente
        double mejora = tiempoSecuencial / tiempoScraping;
        
        System.out.println("   Tiempo secuencial estimado: " + String.format("%.0f", tiempoSecuencial) + "ms");
        System.out.println("   Tiempo concurrente real: " + tiempoScraping + "ms");
        System.out.println("   Mejora de rendimiento: " + String.format("%.1fx", mejora) + " m√°s r√°pido");
        System.out.println("   Eficiencia de paralelizaci√≥n: " + 
                          String.format("%.1f%%", (mejora / tareas.size()) * 100));
        System.out.println();
        
        // Detalles por tarea
        System.out.println("üìã DETALLES POR TAREA:");
        for (int i = 0; i < tareas.size(); i++) {
            ScrapingTask tarea = tareas.get(i);
            String estado = tarea.isExitoso() ? "‚úÖ √âXITO" : "‚ùå ERROR";
            String detalle = tarea.isExitoso() ? 
                           String.format("(%dms)", tarea.getTiempoEjecucion()) :
                           "(" + tarea.getMensajeError() + ")";
            
            System.out.println(String.format("   Noticia %2d: %s %s", 
                                            (i + 1), estado, detalle));
        }
        System.out.println();
        
        // Mostrar errores si los hay
        if (errores > 0) {
            System.out.println("üö® ERRORES ENCONTRADOS:");
            for (int i = 0; i < tareas.size(); i++) {
                ScrapingTask tarea = tareas.get(i);
                if (!tarea.isExitoso()) {
                    System.out.println("   Noticia " + (i + 1) + ": " + tarea.getMensajeError());
                    System.out.println("   URL: " + tarea.getUrl());
                }
            }
            System.out.println();
        }
        
        // Conclusiones
        System.out.println("üéØ CONCLUSIONES:");
        if (exitosos == tareas.size()) {
            System.out.println("   ‚úÖ Todas las noticias fueron procesadas exitosamente");
        } else if (exitosos >= tareas.size() * 0.8) {
            System.out.println("   ‚ö†Ô∏è La mayor√≠a de noticias fueron procesadas exitosamente");
        } else {
            System.out.println("   ‚ùå Se encontraron m√∫ltiples errores en el procesamiento");
        }
        
        if (mejora >= 5) {
            System.out.println("   üöÄ Excelente mejora de rendimiento con concurrencia");
        } else if (mejora >= 2) {
            System.out.println("   ‚úÖ Buena mejora de rendimiento con concurrencia");
        } else {
            System.out.println("   ‚ö†Ô∏è Mejora limitada - posible overhead de concurrencia");
        }
    }
    
    /**
     * Demuestra las ventajas espec√≠ficas de usar Runnable para web scraping
     */
    private static void demostrarVentajasRunnable(List<ScrapingTask> tareas, long tiempoScraping) {
        System.out.println();
        System.out.println("=".repeat(80));
        System.out.println("         VENTAJAS DE RUNNABLE PARA WEB SCRAPING");
        System.out.println("=".repeat(80));
        
        System.out.println("\nüéØ 1. PARALELIZACI√ìN DE I/O BOUND TASKS:");
        System.out.println("   ‚úÖ Web scraping es ideal para concurrencia (I/O intensivo)");
        System.out.println("   ‚úÖ Mientras un hilo espera respuesta HTTP, otros procesan");
        System.out.println("   ‚úÖ Aprovechamiento m√°ximo de tiempo de espera de red");
        
        System.out.println("\nüîÑ 2. FLEXIBILIDAD DE IMPLEMENTACI√ìN:");
        System.out.println("   ‚úÖ Cada ScrapingTask es una unidad de trabajo independiente");
        System.out.println("   ‚úÖ F√°cil reutilizaci√≥n para diferentes sitios web");
        System.out.println("   ‚úÖ Separaci√≥n clara entre l√≥gica de scraping y gesti√≥n de hilos");
        
        System.out.println("\nüéõÔ∏è 3. CONTROL GRANULAR:");
        System.out.println("   ‚úÖ Cada tarea mantiene su propio estado y estad√≠sticas");
        System.out.println("   ‚úÖ Manejo independiente de errores por tarea");
        System.out.println("   ‚úÖ Timeouts y reintentos configurables por tarea");
        
        // Demostrar estad√≠sticas detalladas
        int tareasExitosas = (int) tareas.stream().filter(ScrapingTask::isExitoso).count();
        System.out.println("\nüìä 4. MONITOREO DETALLADO:");
        System.out.println("   ‚úÖ Seguimiento individual de " + tareas.size() + " tareas");
        System.out.println("   ‚úÖ Tasa de √©xito: " + tareasExitosas + "/" + tareas.size());
        System.out.println("   ‚úÖ Tiempos de ejecuci√≥n por tarea disponibles");
        
        System.out.println("\nüß™ 5. TESTABILIDAD SUPERIOR:");
        System.out.println("   ‚úÖ L√≥gica de scraping testeable sin hilos reales");
        System.out.println("   ‚úÖ Mocking sencillo de respuestas HTTP");
        System.out.println("   ‚úÖ Tests unitarios de parsing HTML independientes");
        
        System.out.println("\n‚ö° 6. ESCALABILIDAD:");
        System.out.println("   ‚úÖ F√°cil integraci√≥n con ExecutorService");
        System.out.println("   ‚úÖ Control de n√∫mero m√°ximo de conexiones concurrentes");
        System.out.println("   ‚úÖ Rate limiting implementable por pool de hilos");
        
        System.out.println("\nüèóÔ∏è 7. ARQUITECTURA LIMPIA:");
        System.out.println("   ‚úÖ Responsabilidad √∫nica por clase");
        System.out.println("   ‚úÖ Bajo acoplamiento entre componentes");
        System.out.println("   ‚úÖ Extensible para diferentes tipos de scraping");
        
        System.out.println("\nüìà 8. COMPARACI√ìN CON HERENCIA DE THREAD:");
        System.out.println("   Flexibilidad:     Thread ‚≠ê‚≠ê‚≠ê vs Runnable ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê");
        System.out.println("   Reutilizaci√≥n:    Thread ‚≠ê‚≠ê   vs Runnable ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê");
        System.out.println("   Testabilidad:     Thread ‚≠ê‚≠ê‚≠ê vs Runnable ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê");
        System.out.println("   Escalabilidad:    Thread ‚≠ê‚≠ê‚≠ê vs Runnable ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê");
        System.out.println("   Mantenibilidad:   Thread ‚≠ê‚≠ê‚≠ê vs Runnable ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê");
        
        System.out.println("\nüí° 9. CASOS DE USO REALES:");
        System.out.println("   ‚Ä¢ Agregadores de noticias (Google News, Feedly)");
        System.out.println("   ‚Ä¢ Monitoreo de precios (e-commerce)");
        System.out.println("   ‚Ä¢ An√°lisis de competencia (business intelligence)");
        System.out.println("   ‚Ä¢ Recolecci√≥n de datos para investigaci√≥n");
        
        System.out.println("\n‚ö†Ô∏è 10. CONSIDERACIONES √âTICAS:");
        System.out.println("   ‚Ä¢ Respetar robots.txt y t√©rminos de servicio");
        System.out.println("   ‚Ä¢ Implementar rate limiting apropiado");
        System.out.println("   ‚Ä¢ No sobrecargar servidores objetivo");
        System.out.println("   ‚Ä¢ Uso responsable de datos extra√≠dos");
        
        System.out.println("\n" + "=".repeat(80));
        System.out.println("üèÜ CONCLUSI√ìN: Runnable es la elecci√≥n ideal para web scraping");
        System.out.println("   concurrente, ofreciendo flexibilidad, escalabilidad y");
        System.out.println("   mantenibilidad superior a la herencia de Thread.");
        System.out.println("=".repeat(80));
    }
}
